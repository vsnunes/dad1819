
%
%  $Description: Author guidelines and sample document in LaTeX 2.09$ 
%
%  $Author: ienne $
%  $Date: 1995/09/15 15:20:59 $
%  $Revision: 1.4 $
%

\documentclass[times, 10pt,twocolumn]{article} 
\usepackage{latex8}
\usepackage{times}

%\documentstyle[times,art10,twocolumn,latex8]{article}

%------------------------------------------------------------------------- 
% take the % away on next line to produce the final camera-ready version 
\pagestyle{empty}

%------------------------------------------------------------------------- 
\begin{document}

\title{\LaTeX\ Author Guidelines 
       for {\boldmath $8.5 \times 11$-Inch} Proceedings Manuscripts}

\author{Miguel Belém\\
83531\\
% For a paper whose authors are all at the same institution, 
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'', 
% just like the second author.
\and
Tiago Gonçalves\\
83567\\
\and
Vítor Nunes\\
83576\\
}

\maketitle
\thispagestyle{empty}

\begin{abstract}
   In this project we will apply two different aproaches to solve the problem of
   having a distributed tupplespace. 
   These aproaches have different tradeoffs considerations regarding time spent 
   executing a request, network congestion and time spent recovering from a fault.
   For this work we consider a perfect failure detector, in which if a server stop
   responding to requests, then is because it crashed.   
\end{abstract}



%------------------------------------------------------------------------- 
\Section{Introduction}

%Please follow the steps outlined below when submitting your 
%manuscript to the IEEE Computer Society Press. Note there have 
%been some changes to the measurements from previous instructions.
A tuple space consists in distributed collection of tuples. A tuple contains
fields that are some how related.
A basic tuple space needs to be writable, readable and deletable.

\textbf{Challenges.} At a first glace seems easy to implement a tuple space
in a distributed way however problems like consistency, data loss and 
performance rise.

To overcome this challenges we propose two diferent implementations of a 
distributed tuple space which solve the challenges listed above.

The State Machine Replication (SMR) which uses a coordination mechanism envolving
one leader to be responsible for coordination.

And a Xu and Liskov implementation that discards the need of a leader to
coordinate client's requests.


%------------------------------------------------------------------------- 
\Section{State Machine Replcation}

The State Machine Replication is based on primary backup approach. Given one
primary and several secondary nodes, clients will perform requests to the
primary node only.

When the first server is switched on, we start by searching for alive servers
requesting \textsc{AreYouTheMaster}. If no reply is given then the server
becomes the leader. When others servers join the process repeats but they
will receive the reply containing the URL path of the master.

%------------------------------------------------------------------------- 
\SubSection{Clients request}

In our solution when the client starts we begin with a list of all URL's servers,
sends the request to all servers and only the leader will start processing, others
simply discard the request.

%------------------------------------------------------------------------- 
\SubSection{Fault tolerance}
This implementation has an obvious \textbf{week point}: if the master crashes 
the system will stop repling to requests.
Our solution to this problem consists of using an heartbeat that is sent from the
secondary nodes to the primary node every random seconds between 3 to 10 seconds.
This ensures that in the worst case the system will took ten seconds to
recovers (assuming instant propagation of messages) . 
The randomization process is used to optimize network bandwith and
prevent heartbeats flooding on the master.

Every node in the SMR contains an identifier. When a master crashes the remaining
node with the smallest ID will be elect as the new master. It starts by informing
all secondary nodes about its leadership change. By that time all secondary nodes
start sending heartbeets to the new master.

Another problem is when a \textbf{secondary node crashes}. In this case the
availability of the system is not affected since the primary node continues 
to receive client's request. Nevertheless if that same node resurrects then it
will be unconsistent with others. To fix this problem, every node has a log.

A log is used to keep track of every request made by the master 
\textbf{that was already executed.} When a secondary node crashes and recovers
it will have no such tuple in the tuple space, then request to the master
a copy of his own log. The master suspend the client's requests processing and
replies to the new secondary node. As soon the new node is ready the master
continues to processing client's request.


%------------------------------------------------------------------------- 
\Section{Xu and Liskov}

De acordo com esta implementação já não se recorre a um master que garante a 
consistência do sistema coordenando todos os pedidos. Em vez disso,
cada Front end de cada cliente vai propagar o pedido para todos os servidores vivos,
e cada um desses servidores vai tratar de o executar.

%------------------------------------------------------------------------- 
\SubSection{Clients request}

Na nossa solução, quando um cliente quer realizar uma lista de um ou mais pedidos,
vai inicialmente criar um Front End, que vai procurar quais os servidores vivos,
e com isso é criada a View do cliente, que tem um ID. 
Quando um pedido é enviado para os servidores, é anexado ao mesmo o ID da view do cliente,
o que permite ao servidor saber se a view do cliente está ou não sincronizada com as views
dos servidores, caso não esteja, é porque o sistema sofreu uma modificação e quando recuperar da mesma,
a nova é enviada ao cliente.

%------------------------------------------------------------------------- 
 
\SubSection{Fault tolerance}

Esta abordagem, ao não apresentar um master, tem a vantagem de que quando um nó crasha,
seja ele qual for, o sistema não precisa de parar. Isto é possível pois não existe uma
unidade central da qual todo o sistema dependa, e que caso a mesma crashe, todo o sistema 
é comprometido.
Apresenta uma desvantagem em relação ao SMR que é a de precisar de parar o sistema por 
breves instantes quando um novo nó se liga ao sistema. Isto é feito pois as Views precisam
de ser atualizadas para passar a conter o novo nó, e não se podem perder pedidos que
estejam a ser feitos enquanto as Views são atualizadas.

Quando um nó crasha o cliente vai atualizar a sua view, e informar todos os seus membros
para atualizarem a deles.
Quando um nó rescuscita, vai começar por informar todas as máquinas vivas de que precisa
do seu espaço de tuplos e vai pedir para que atualizem as suas views. Cada máquina ao
receber este pedido vai recusar pedidos dos clientes que apresentem uma view antiga
e vai dar o seu tuplespace ao novo nó. 
O novo nó vai fazer uma interseção de todos os tuplespaces (a interseção garante
que ele apenas vai guardar os pedidos que já foram executados em todas as máquinas).
Em seguida esse tuplespace é propagado para todo o sistema, com isto garantimos que 
nunca se perdem pedidos, pois mesmo que um pedido já tenha sido enviado para uma máquina
mas não para outra, vai acabar ser repetido. Após todos os tuplespaces terem sido
atualizados, o novo nó sinaliza as outras máquinas para que mandem a sua nova view ao cliente,
repetindo o mesmo todos os pedidos da mesma operação que foram enviados numa view antiga e que
consequentemente foram recusados pelos servidores.

%------------------------------------------------------------------------- 
\Section{Evaluation}
Nesta secção vamos analisar e avaliar como cada algorítmo se comporta no que toca 
a alguns pontos chaves. Apresentamos ainda a justificação para algumas escolhas que
tiveram de ser feitas.
\SubSection{Requests execution}
\subsubsection{SMR}

Para a operação de Take e Write é necessário que os pedidos cheguem ao master
e depois este propaga para o resto dos servidores/réplicas. Isto além de sobrecarregar um servidor pois 
é ele que tem de receber a transmitir os pedidos e posteriormente esperar pelas respostas 
dadas pelas réplicas também atrasa a respostas aos pedidos pois é preciso que os mesmo passem
por um intermediário.
Na operação de Read os pedidos não são propagados pera as réplicas, devolvendo o master 
instantâneamente a resposta ao cliente, caso seja possível (Take e Read são operações bloquentas, 
para ser dada uma resposta é preciso que a mesma conste nos espaços de tuplos).

\subsubsection{XL}

Para a operação Write o cliente propaga o pedido para todos os servidores. Para a operação de Read
o cliente propaga o pedido para todos os servidores e devolve ao cliente quando obtiver a primeira
resposta. Para a operação de Take foram tidos em conta alguns cuidados, nomeadamente: é necessário
bloquear certas entradas do espaço de tuplos e convem que esta parte seja feita de uma maneira que 
não obrigue a que o cliente fique muito tempo à espera de uma resposta assim sendo o algorítmo usado
foi o de tentar bloquear tantas entradas que dêm match com o pedido quanto possível, e quando não for 
possível adquirir o trinco de uma dada entrada, o conjunto de entradas que cujo trinco foi adquirido
sao devolvidas ao front end, em seguida o front end vai intersetar os conjuntos que recebeu dos vários
servidores e vai escolher um elemento comum a todos esses conjuntos e remove-lo, devolvendo ao cliente.
Esta foi a melhor solução encontrada, pois usamos uma heurística que tenta devolver o máximo de entradas
possível no entanto não fica muito tempo à espera de modo a conseguir todas a entradas possíveis (se existirem
muitos pedidos simultâneos e todos fizerem isto, o que vai aconter é o servidor não conseguir dar resposta a ninguém
e ficar muito lento), esta heurística também não se contenta apenas com uma resposta (caso só fosse devolvida uma entrada,
na parte da interseção, a probabilidade de a mesma ser nula seria muito elevada). Com esta heurística conseguimos
ter algum equilíbrio.

\SubSection{Comparison}

Para a operação Write é expectável que o XL a execute mais rapidamente.
Para a operação de Read é expectável que ambas as implementações tenham um tempo de execução semelhante.
Para a operação de Take se a máquina master tiver uma capacidade de processamente muito elevada (não entupir com
um elevado número de pedidos), acabamos por conseguir ter tempos de resposta mais baixos pois não ficamos dependentes
da operação de interseção, que pode falhar, tendo de ser repetido todo o processo.

\SubSection{Network congestion}
\subsubsection{SMR}
\subsubsection{XL}
\SubSection{Fault recovering}
\subsubsection{SMR}
\subsubsection{XL}
\Section{Summary and conclusions}
No algorítmo SMR não são usadas Views, provocando uma latência enorme em todas as comunicações servidor servidor
e cliente servidor, pois é necessário estar sempre a verificar que máquinas estão vivas. Uma modificação futura a este
trabalho seria implementar um sistema de Views semelhante ao existente no XL.
Não é possível dizer qual dos algorítmos é melhor, ambos apresentam vantagens e desvantagens, será necessário ver com atenção
os tópicos referentes à Evaluation, e conforme o intuíto do sistema a ser desenvolvido, aplicar o que melhor se adeque aos objetivos
do sistema.


%------------------------------------------------------------------------- 
\nocite{ex1,ex2}
\bibliographystyle{latex8}
\bibliography{latex8}

\end{document}

